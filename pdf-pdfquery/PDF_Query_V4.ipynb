{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597a3f60",
   "metadata": {},
   "source": [
    "#### Extracting PDF Information using `PDFQuery`\n",
    "\n",
    "v4.0.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7ce93",
   "metadata": {},
   "source": [
    "#### Input and Output Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31143d51",
   "metadata": {},
   "source": [
    "Set to the directory the contains the DCM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bac8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Volumes/glaucoma/SHILEY_VISUAL_FIELDS/20220907_24-2/SFA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc636b3c",
   "metadata": {},
   "source": [
    "Set to the directory where the PDFs will be placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e1ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/Volumes/glaucoma/SHILEY_VISUAL_FIELDS/20220907_24-2/SFA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573f5fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed3f28",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fbdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_message = \"There may be other dependencies you need to install, you can let Nicole know\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Imports that sometimes cause troubles\n",
    "\n",
    "# PDF Query\n",
    "try:\n",
    "    import pdfquery as pq\n",
    "except:\n",
    "    !pip install pdfquery\n",
    "    try: \n",
    "        import pdfquery as pq\n",
    "    except:\n",
    "        print(import_message)\n",
    "\n",
    "\n",
    "        \n",
    "# PIL\n",
    "try: \n",
    "    import PIL.Image as Image\n",
    "except:\n",
    "    !pip install pillow\n",
    "    try:\n",
    "        import PIL.Image as Image\n",
    "    except:\n",
    "        print(import_message)\n",
    "\n",
    "        \n",
    "        \n",
    "# pdf2image\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "except:\n",
    "    !pip install pdf2image\n",
    "    try:\n",
    "        from pdf2image import convert_from_path\n",
    "    except:\n",
    "        print(import_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d560f7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1881a",
   "metadata": {},
   "source": [
    "#### Important Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98929455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files\n",
    "files = [x for x in os.listdir(input_dir) if x.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f7e04",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a022fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for output\n",
    "cols = ['Batch_UID', 'Exam_UID', 'InstrumentModel', 'InstrumentSerialNumber', \n",
    "        'InstrumentSoftwareVersion', 'PatientID', 'GIVEN_NAME', 'LAST_NAME', \n",
    "        'StudyCode', 'aeDOB', 'Eye', 'SeriesDateTime',\n",
    "        'aeExamDate', 'aeExamTime', 'ExamDuration', 'aeIsShileyClinicHFAExam', 'aeDIGSTestType',\n",
    "        'TestType', 'TestPattern', 'TestStrategy', 'StimulusColor', 'StimulusSize', \n",
    "        'BackgroundColor', 'FixationTarget', 'FixationMonitor', 'TrialRXSphereRaw', \n",
    "        'TrialRXCylRaw', 'TrialRXAxisRaw', 'PupilDiameter', 'VAType', 'BlindSpotX','BlindSpotY',\n",
    "        'BlindSpotStimulusSize', 'FalseNegativePercent', 'FalsePositivePercent',\n",
    "        'aeFixationCheckPercentage', 'FovealResult', 'FovealThreshold', 'ClinicalNotes',\n",
    "        'SFStatus', 'SF', 'SFProb', 'SWAPFTGeneralHeight', 'GHTType', 'MD', 'MDProb', 'PSD',\n",
    "        'PSDProb', 'CPSD', 'CPSDProb', 'FovealThresholdProb', 'aePDPCen4LT5Count', \n",
    "        'aeHasHighRawThreshold', 'FLAGAssessment', 'FLAGSeverity', 'AGISScore', 'AGISNas', \n",
    "        'AGISInf', 'AGISSup', 'GHSupThrSum', 'GHSupThrMean', 'GHSupThrStd', 'GHSupTDSum',\n",
    "        'GHSupTDMean', 'GHSupTDStd', 'GHSupPDSum', 'GHSupPDMean', 'GHSupPDStd', 'GHSupPDCntLT50p',\n",
    "        'GHSupPDCntLT10p', 'GHSupNasThrSum', 'GHSupNasThrMean', 'GHSupNasThrStd', 'GHSupNasTDSum',\n",
    "        'GHSupNasTDMean', 'GHSupNasTDStd', 'GHSupNasPDSum', 'GHSupNasPDMean', 'GHSupNasPDStd',\n",
    "        'GHSupNasPDCntLT50p', 'GHSupNasPDCntLT10p', 'GHInfThrSum', 'GHInfThrMean', 'GHInfThrStd',\n",
    "        'GHInfTDSum', 'GHInfTDMean', 'GHInfTDStd', 'GHInfPDSum', 'GHInfPDMean', 'GHInfPDStd',\n",
    "        'GHInfPDCntLT50p', 'GHInfPDCntLT10p', 'GHInfNasThrSum', 'GHInfNasThrMean', 'GHInfNasThrStd',\n",
    "        'GHInfNasTDSum', 'GHInfNasTDMean', 'GHInfNasTDStd', 'GHInfNasPDSum', 'GHInfNasPDMean',\n",
    "        'GHInfNasPDStd', 'GHInfNasPDCntLT50p', 'GHInfNasPDCntLT10p', 'GHCentralThrSum',\n",
    "        'GHCentralThrMean', 'GHCentralThrStd', 'GHCentralTDSum', 'GHCentralTDMean', 'GHCentralTDStd',\n",
    "        'GHCentralPDSum', 'GHCentralPDMean', 'GHCentralPDStd', 'GHCentralPDCntLT50p', \n",
    "        'GHCentralPDCntLT10p', 'GHTemporalThrSum', 'GHTemporalThrMean', 'GHTemporalThrStd',\n",
    "        'GHTemporalTDSum', 'GHTemporalTDMean', 'GHTemporalTDStd', 'GHTemporalPDSum', \n",
    "        'GHTemporalPDMean', 'GHTemporalPDStd', 'GHTemporalPDCntLT50p', 'GHTemporalPDCntLT10p',\n",
    "        'N9_S27_Thr', 'N3_S27_Thr', 'T3_S27_Thr', 'T9_S27_Thr', 'N15_S21_Thr', 'N9_S21_Thr',\n",
    "        'N3_S21_Thr', 'T3_S21_Thr', 'T9_S21_Thr', 'T15_S21_Thr', 'N21_S15_Thr', 'N15_S15_Thr', \n",
    "        'N9_S15_Thr', 'N3_S15_Thr', 'T3_S15_Thr', 'T9_S15_Thr', 'T15_S15_Thr', 'T21_S15_Thr',\n",
    "        'N27_S9_Thr', 'N21_S9_Thr', 'N15_S9_Thr', 'N9_S9_Thr', 'N3_S9_Thr', 'T3_S9_Thr', 'T9_S9_Thr',\n",
    "        'T15_S9_Thr', 'T21_S9_Thr', 'T27_S9_Thr', 'N27_S3_Thr', 'N21_S3_Thr', 'N15_S3_Thr', \n",
    "        'N9_S3_Thr',  'N3_S3_Thr', 'T3_S3_Thr', 'T9_S3_Thr', 'T21_S3_Thr', 'T27_S3_Thr', \n",
    "        'N27_I3_Thr', 'N21_I3_Thr', 'N15_I3_Thr', 'N9_I3_Thr', 'N3_I3_Thr', 'T3_I3_Thr', 'T9_I3_Thr', \n",
    "        'T21_I3_Thr', 'T27_I3_Thr', 'N27_I9_Thr', 'N21_I9_Thr', 'N15_I9_Thr', 'N9_I9_Thr', \n",
    "        'N3_I9_Thr', 'T3_I9_Thr', 'T9_I9_Thr', 'T15_I9_Thr', 'T21_I9_Thr', 'T27_I9_Thr', \n",
    "        'N21_I15_Thr', 'N15_I15_Thr', 'N9_I15_Thr', 'N3_I15_Thr', 'T3_I15_Thr', 'T9_I15_Thr', \n",
    "        'T15_I15_Thr', 'T21_I15_Thr', 'N15_I21_Thr', 'N9_I21_Thr', 'N3_I21_Thr', 'T3_I21_Thr',\n",
    "        'T9_I21_Thr', 'T15_I21_Thr', 'N9_I27_Thr', 'N3_I27_Thr', 'T3_I27_Thr', 'T9_I27_Thr', \n",
    "        'N9_S27_TD', 'N3_S27_TD', 'T3_S27_TD', 'T9_S27_TD', 'N15_S21_TD', 'N9_S21_TD', 'N3_S21_TD', \n",
    "        'T3_S21_TD', 'T9_S21_TD', 'T15_S21_TD', 'N21_S15_TD', 'N15_S15_TD', 'N9_S15_TD', 'N3_S15_TD',\n",
    "        'T3_S15_TD', 'T9_S15_TD', 'T15_S15_TD', 'T21_S15_TD', 'N27_S9_TD', 'N21_S9_TD', 'N15_S9_TD', \n",
    "        'N9_S9_TD', 'N3_S9_TD', 'T3_S9_TD', 'T9_S9_TD', 'T15_S9_TD', 'T21_S9_TD', 'T27_S9_TD', \n",
    "        'N27_S3_TD', 'N21_S3_TD', 'N15_S3_TD', 'N9_S3_TD', 'N3_S3_TD', 'T3_S3_TD', 'T9_S3_TD', \n",
    "        'T21_S3_TD', 'T27_S3_TD', 'N27_I3_TD', 'N21_I3_TD', 'N15_I3_TD', 'N9_I3_TD', 'N3_I3_TD',\n",
    "        'T3_I3_TD', 'T9_I3_TD', 'T21_I3_TD', 'T27_I3_TD', 'N27_I9_TD', 'N21_I9_TD', 'N15_I9_TD', \n",
    "        'N9_I9_TD', 'N3_I9_TD', 'T3_I9_TD', 'T9_I9_TD', 'T15_I9_TD', 'T21_I9_TD', 'T27_I9_TD',\n",
    "        'N21_I15_TD', 'N15_I15_TD', 'N9_I15_TD', 'N3_I15_TD', 'T3_I15_TD', 'T9_I15_TD', 'T15_I15_TD',\n",
    "        'T21_I15_TD', 'N15_I21_TD', 'N9_I21_TD', 'N3_I21_TD', 'T3_I21_TD', 'T9_I21_TD', 'T15_I21_TD',\n",
    "        'N9_I27_TD', 'N3_I27_TD', 'T3_I27_TD', 'T9_I27_TD', 'N9_S27_PD', 'N3_S27_PD', 'T3_S27_PD', \n",
    "        'T9_S27_PD', 'N15_S21_PD', 'N9_S21_PD', 'N3_S21_PD', 'T3_S21_PD', 'T9_S21_PD', 'T15_S21_PD',\n",
    "        'N21_S15_PD', 'N15_S15_PD', 'N9_S15_PD', 'N3_S15_PD', 'T3_S15_PD', 'T9_S15_PD', 'T15_S15_PD',\n",
    "        'T21_S15_PD', 'N27_S9_PD', 'N21_S9_PD', 'N15_S9_PD', 'N9_S9_PD', 'N3_S9_PD', 'T3_S9_PD', \n",
    "        'T9_S9_PD', 'T15_S9_PD', 'T21_S9_PD', 'T27_S9_PD', 'N27_S3_PD', 'N21_S3_PD', 'N15_S3_PD', \n",
    "        'N9_S3_PD', 'N3_S3_PD', 'T3_S3_PD', 'T9_S3_PD', 'T21_S3_PD', 'T27_S3_PD', 'N27_I3_PD',\n",
    "        'N21_I3_PD', 'N15_I3_PD', 'N9_I3_PD', 'N3_I3_PD', 'T3_I3_PD', 'T9_I3_PD', 'T21_I3_PD', \n",
    "        'T27_I3_PD', 'N27_I9_PD', 'N21_I9_PD', 'N15_I9_PD', 'N9_I9_PD', 'N3_I9_PD', 'T3_I9_PD', \n",
    "        'T9_I9_PD', 'T15_I9_PD', 'T21_I9_PD', 'T27_I9_PD', 'N21_I15_PD', 'N15_I15_PD', 'N9_I15_PD',\n",
    "        'N3_I15_PD', 'T3_I15_PD', 'T9_I15_PD', 'T15_I15_PD', 'T21_I15_PD', 'N15_I21_PD', 'N9_I21_PD', \n",
    "        'N3_I21_PD', 'T3_I21_PD', 'T9_I21_PD', 'T15_I21_PD', 'N9_I27_PD', 'N3_I27_PD', 'T3_I27_PD',\n",
    "        'T9_I27_PD', 'N9_S27_TDP', 'N3_S27_TDP', 'T3_S27_TDP', 'T9_S27_TDP', 'N15_S21_TDP', 'N9_S21_TDP', \n",
    "        'N3_S21_TDP', 'T3_S21_TDP', 'T9_S21_TDP', 'T15_S21_TDP', 'N21_S15_TDP', 'N15_S15_TDP', \n",
    "        'N9_S15_TDP', 'N3_S15_TDP', 'T3_S15_TDP', 'T9_S15_TDP', 'T15_S15_TDP', 'T21_S15_TDP', \n",
    "        'N27_S9_TDP', 'N21_S9_TDP', 'N15_S9_TDP', 'N9_S9_TDP', 'N3_S9_TDP', 'T3_S9_TDP', 'T9_S9_TDP', \n",
    "        'T15_S9_TDP', 'T21_S9_TDP', 'T27_S9_TDP', 'N27_S3_TDP', 'N21_S3_TDP', 'N15_S3_TDP', 'N9_S3_TDP', \n",
    "        'N3_S3_TDP', 'T3_S3_TDP', 'T9_S3_TDP', 'T21_S3_TDP', 'T27_S3_TDP', 'N27_I3_TDP', 'N21_I3_TDP',\n",
    "        'N15_I3_TDP', 'N9_I3_TDP', 'N3_I3_TDP', 'T3_I3_TDP', 'T9_I3_TDP', 'T21_I3_TDP', 'T27_I3_TDP',\n",
    "        'N27_I9_TDP', 'N21_I9_TDP', 'N15_I9_TDP', 'N9_I9_TDP', 'N3_I9_TDP', 'T3_I9_TDP', 'T9_I9_TDP',\n",
    "        'T15_I9_TDP', 'T21_I9_TDP', 'T27_I9_TDP', 'N21_I15_TDP', 'N15_I15_TDP', 'N9_I15_TDP', \n",
    "        'N3_I15_TDP', 'T3_I15_TDP', 'T9_I15_TDP', 'T15_I15_TDP', 'T21_I15_TDP', 'N15_I21_TDP', \n",
    "        'N9_I21_TDP', 'N3_I21_TDP', 'T3_I21_TDP', 'T9_I21_TDP', 'T15_I21_TDP', 'N9_I27_TDP', \n",
    "        'N3_I27_TDP', 'T3_I27_TDP', 'T9_I27_TDP', 'N9_S27_PDP', 'N3_S27_PDP', 'T3_S27_PDP', \n",
    "        'T9_S27_PDP', 'N15_S21_PDP', 'N9_S21_PDP', 'N3_S21_PDP', 'T3_S21_PDP', 'T9_S21_PDP', \n",
    "        'T15_S21_PDP', 'N21_S15_PDP', 'N15_S15_PDP', 'N9_S15_PDP', 'N3_S15_PDP', 'T3_S15_PDP', \n",
    "        'T9_S15_PDP', 'T15_S15_PDP', 'T21_S15_PDP', 'N27_S9_PDP', 'N21_S9_PDP', 'N15_S9_PDP',\n",
    "        'N9_S9_PDP', 'N3_S9_PDP', 'T3_S9_PDP', 'T9_S9_PDP', 'T15_S9_PDP', 'T21_S9_PDP', 'T27_S9_PDP', \n",
    "        'N27_S3_PDP', 'N21_S3_PDP', 'N15_S3_PDP', 'N9_S3_PDP', 'N3_S3_PDP', 'T3_S3_PDP', \n",
    "        'T9_S3_PDP', 'T21_S3_PDP', 'T27_S3_PDP', 'N27_I3_PDP', 'N21_I3_PDP', 'N15_I3_PDP',\n",
    "        'N9_I3_PDP', 'N3_I3_PDP', 'T3_I3_PDP', 'T9_I3_PDP', 'T21_I3_PDP', 'T27_I3_PDP',\n",
    "        'N27_I9_PDP', 'N21_I9_PDP', 'N15_I9_PDP', 'N9_I9_PDP', 'N3_I9_PDP', 'T3_I9_PDP', \n",
    "        'T9_I9_PDP', 'T15_I9_PDP', 'T21_I9_PDP', 'T27_I9_PDP', 'N21_I15_PDP', 'N15_I15_PDP',\n",
    "        'N9_I15_PDP', 'N3_I15_PDP', 'T3_I15_PDP', 'T9_I15_PDP', 'T15_I15_PDP', 'T21_I15_PDP',\n",
    "        'N15_I21_PDP', 'N9_I21_PDP', 'N3_I21_PDP', 'T3_I21_PDP', 'T9_I21_PDP', 'T15_I21_PDP',\n",
    "        'N9_I27_PDP', 'N3_I27_PDP', 'T3_I27_PDP', 'T9_I27_PDP', 'cAutoQCStatus', 'QCFieldUsable',\n",
    "        'QCReliable', 'cQCFN33Status', 'cQCAHSManualStatus', 'cQCRimArtifactStatus',\n",
    "        'cQCInattentionStatus', 'cQCLearningEffectStatus', 'cQCFatigueStatus', 'cQCFixationStatus', \n",
    "        'cQCOtherDefectStatus', 'cQCUnreliableByTechnicianStatus', 'cQCUnaccPupilSizeStatus','VFI',\n",
    "        'kPrevUsable_ExamTimeStamp', 'aeExamTimeStamp', 'kNextUsable_ExamTimeStamp', \n",
    "        'kPrevUsable_FLAGAssessment', 'kNextUsable_FLAGAssessment', \n",
    "        'cFLAG_Confirmation_Status_ByTestType', 'cIsABNORMAL_FLAG_Confirmed_ByTestType',\n",
    "        'cIsNORMAL_FLAG_Confirmed_ByTestType', 'cCnt_TDP_LessThan5', 'cCnt_PDP_LessThan5',\n",
    "        'cCnt_TDP_LessThan2', 'cCnt_PDP_LessThan2', 'cCnt_TDP_LessThan1', 'cCnt_PDP_LessThan1',\n",
    "        'cCnt_TDP_LessThan05', 'cCnt_PDP_LessThan05', 'kUsedADAGESBL09','sFLAGAbn3ConsecConfirmed',\n",
    "        'sFLAGAbn3ConsecUnconfirmed', 'sFLAGNorm3ConsecConfirmed', 'sFLAGNorm3ConsecUnconfirmed',\n",
    "        'LowPatientReliabilityStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872a4d1",
   "metadata": {},
   "source": [
    "#### Functions for PDF Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d671a",
   "metadata": {},
   "source": [
    "#### `overlaps_bbox`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8d3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps_bbox(pdf, bbox):\n",
    "    text_query = pdf.pq(f'''LTTextLineHorizontal:overlaps_bbox(\"{','.join([str(int(coord)) for coord in bbox])}\")''')\n",
    "    text_query = [item.layout.get_text() for item in text_query]\n",
    "    return text_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52656e26",
   "metadata": {},
   "source": [
    "#### `contains_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbd26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_query(pdf, pattern):\n",
    "    text_query = pdf.pq(f'''LTTextLineHorizontal:contains(\"{pattern}\")''')\n",
    "    return text_query[0].layout.get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9059052",
   "metadata": {},
   "source": [
    "#### `key_value_output`\n",
    "\n",
    "Takes in a pdf object and converts the main text fields to key value pairs. These key value pairs are stored in a dictionary for further querying and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9b062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_value_output(pdf):\n",
    "    \n",
    "    # Empty dictionary to be populated\n",
    "    info = {}\n",
    "    \n",
    "    # Patient Info\n",
    "    p_pats = [\"Patient\", \"Date of Birth\", \"Gender\", \"Patient ID\"]\n",
    "    p_info = [contains_query(pdf, pat).split(':') for pat in p_pats]\n",
    "    p_info = dict(map(lambda x: [x[0], x[1].strip()], p_info))\n",
    "    \n",
    "    info.update(p_info)\n",
    "    \n",
    "    # Eye Info\n",
    "    e_pats = [\"Fixation Monitor\", \"Fixation Target\", \"Fixation Losses\", \"False POS Errors\",\n",
    "              \"False NEG Errors\", \"Test Duration\", \"Stimulus\", \"Background\", \"Strategy\",\n",
    "              \"Pupil Diameter\", \"Visual Acuity\", \"Rx\", \"Date:\", \"Time\", \"Age\", \"Fovea\"]\n",
    "    \n",
    "    for i, x in enumerate(e_pats):\n",
    "        \n",
    "        bbox = list(pdf.pq(f'LTTextLineHorizontal:contains(\"{x}\")')[0].layout.bbox)\n",
    "        bbox[2] += 100\n",
    "        temp = overlaps_bbox(pdf, bbox)\n",
    "        \n",
    "        if len(temp) == 1:\n",
    "            temp = temp[0].split(\":\")\n",
    "            \n",
    "        if not temp[0].startswith(x):\n",
    "            temp[0], temp[1] = temp[1], temp[0]\n",
    "\n",
    "        try:\n",
    "            key = temp[0].strip().strip(\":\")\n",
    "            val = temp[1].strip()\n",
    "\n",
    "        except IndexError:\n",
    "            key = temp[0].strip().strip(\":\")\n",
    "            val = \"\"\n",
    "\n",
    "        info[key] = val \n",
    "        \n",
    "    # Other info\n",
    "    o_pats = [\"GHT\", \"VFI\", \"MD\", \"PSD\"]\n",
    "    \n",
    "    for i, x in enumerate(o_pats):\n",
    "        \n",
    "        bbox = list(pdf.pq(f'LTTextLineHorizontal:contains(\"{x}\")')[0].layout.bbox)\n",
    "        bbox[2] += 100\n",
    "        temp = overlaps_bbox(pdf, bbox)\n",
    "        \n",
    "        if len(temp) == 1:\n",
    "            temp = temp[0].split(\":\")\n",
    "            \n",
    "        if not temp[0].startswith(x):\n",
    "            temp[0], temp[1] = temp[1], temp[0]\n",
    "        \n",
    "        try:\n",
    "            val = temp[1].strip()\n",
    "\n",
    "        except IndexError:\n",
    "            val = \"\"\n",
    "\n",
    "        info[x] = val \n",
    "        \n",
    "    try:\n",
    "        info[\"Reliability\"] = contains_query(pdf, '***').strip(\"***\").strip()\n",
    "    except:\n",
    "        info[\"Reliability\"] = \"\"\n",
    "        \n",
    "    info[\"Eye\"] = pdf.pq('LTTextLineHorizontal:contains(\"Single Field Analysis\")')[0]\\\n",
    "    .layout.get_text()[:2]\n",
    "    \n",
    "    # Footer\n",
    "    footer_bbox = list(pdf.pq(f'LTTextLineHorizontal:contains(\"Version\")')[0].layout.bbox)\n",
    "    footer_bbox[0] = 0\n",
    "    footer_bbox[2] = 560\n",
    "    info[\"Instrument\"], info[\"Version\"], info[\"Created\"] = overlaps_bbox(pdf, footer_bbox)[:-1]\n",
    "    \n",
    "    info[\"Test Pattern\"] = contains_query(pdf, \"Threshold Test\")\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9540977",
   "metadata": {},
   "source": [
    "#### `clean_output`\n",
    "\n",
    "Formats values of a dictionary produced by `key_value_output`. Stores the newly cleaned values in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e4165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(info, output):\n",
    "    \n",
    "    # Save the keys in a Series\n",
    "    KEYS = pd.Series(info.keys())\n",
    "    \n",
    "    # Important Dates\n",
    "    DOB = pd.to_datetime(info[\"Date of Birth\"])\n",
    "    VIS = pd.to_datetime(info[\"Date\"])\n",
    "    \n",
    "    # Patient Info\n",
    "    output[\"PatientID\"]  = info[\"Patient ID\"]\n",
    "    \n",
    "    try:\n",
    "        output[\"GIVEN_NAME\"] = info[\"Patient\"].split(\",\")[1]\n",
    "    except IndexError:\n",
    "        output[\"GIVEN_NAME\"] = \"\"\n",
    "        \n",
    "    output[\"LAST_NAME\"]  = info[\"Patient\"].strip(\",\")\n",
    "    output[\"aeDOB\"] = str(DOB.month) + \"/\" + str(DOB.day) + \"/\" + str(DOB.year) #[-2:]\n",
    "    \n",
    "    # Visit Info\n",
    "    output[\"aeExamTime\"] = info[\"Time\"].split()[0]\n",
    "    output[\"aeExamDate\"] = str(VIS.month) + \"/\" + str(VIS.day) + \"/\" + str(VIS.year) #[-2:]\n",
    "    output[\"TestStrategy\"] = info[\"Strategy\"]\n",
    "    output[\"ExamDuration\"] = info[\"Test Duration\"]\n",
    "    \n",
    "    # Eye Info\n",
    "    try:\n",
    "        output[\"VAType\"] = float(info[\"Visual Acuity\"])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    MDKEY  = KEYS[KEYS.str.contains(\"MD\").idxmax()]\n",
    "    PSDKEY = KEYS[KEYS.str.contains(\"PSD\").idxmax()]\n",
    "    \n",
    "    # MD and MDProb\n",
    "    if info[MDKEY].endswith(\"dB\"):\n",
    "        output[\"MD\"]     = info[MDKEY].strip(\" dB\")\n",
    "        output[\"MDProb\"] = \"Not Significant\"\n",
    "        \n",
    "    elif info[MDKEY].endswith(\"%\"):\n",
    "        output[\"MD\"]     = info[MDKEY].split(\" dB \")[0]\n",
    "        output[\"MDProb\"] = info[MDKEY].split(\" dB \")[1]\n",
    "\n",
    "    \n",
    "    # PSD and PSDProb\n",
    "    if info[PSDKEY].endswith(\"dB\"):\n",
    "        output[\"PSD\"]     = info[PSDKEY].strip(\" dB\")\n",
    "        output[\"PSDProb\"] = \"Not Significant\"\n",
    "        \n",
    "    elif info[PSDKEY].endswith(\"%\"):\n",
    "        output[\"PSD\"]     = info[PSDKEY].split(\" dB \")[0]\n",
    "        output[\"PSDProb\"] = info[PSDKEY].split(\" dB \")[1]\n",
    "\n",
    "    \n",
    "    # Other Info\n",
    "    output[\"FixationTarget\"]  = info[\"Fixation Target\"]\n",
    "    output[\"FixationMonitor\"] = info[\"Fixation Monitor\"]\n",
    "    output[\"StimulusSize\"]    = info[\"Stimulus\"].split(\", \")[0]\n",
    "    output[\"StimulusColor\"]   = info[\"Stimulus\"].split()[1]\n",
    "    output[\"BackgroundColor\"] = output[\"StimulusColor\"] + \" (\" + info[\"Background\"] + \")\"\n",
    "    \n",
    "    try:\n",
    "        output[\"PupilDiameter\"]   = info[\"Pupil Diameter\"].split()[0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    output[\"FovealThreshold\"] = info[\"Fovea\"].split()[0]\n",
    "    output[\"GHTType\"]         = info[\"GHT\"]\n",
    "    output[\"VFI\"]             = info[\"VFI\"].strip(\"%\")\n",
    "    \n",
    "    err, trials = info[\"Fixation Losses\"].split()[0].split(\"/\")\n",
    "    output[\"aeFixationCheckPercentage\"] = round(float(err) / float(trials) * 100, 2)\n",
    "    output[\"FalsePositivePercent\"] = info[\"False POS Errors\"].strip(\" XX\").strip(\"%\")\n",
    "    output[\"FalseNegativePercent\"] = info[\"False NEG Errors\"].strip(\" XX\").strip(\"%\")\n",
    "    \n",
    "    # Populate the data frame with other acquired info\n",
    "    output[\"Eye\"]              = info[\"Eye\"]\n",
    "    output[\"TestType\"]         = info[\"Test Pattern\"].split()[2]\n",
    "    output[\"TestPattern\"]      = info[\"Test Pattern\"].split()[0] + info[\"Test Pattern\"].split()[1]\n",
    "    \n",
    "    try:\n",
    "        output[\"TrialRXSphereRaw\"] = re.findall(\"(\\d+\\.\\d+)\\s?DS\", info[\"Rx\"])[0]\n",
    "    except:\n",
    "        output[\"TrialRXSphereRaw\"] = \"\"\n",
    "        \n",
    "    try:\n",
    "        output[\"TrialRXCylRaw\"]    = re.findall(\"(\\d+\\.\\d+)\\s?DC\", info[\"Rx\"])[0]\n",
    "    except:\n",
    "        output[\"TrialRXCylRaw\"]    = \"\"\n",
    "    \n",
    "    try:\n",
    "        output[\"TrialRXAxisRaw\"]   = re.findall(\"X(.*)\", info[\"Rx\"])[0]\n",
    "    except:\n",
    "        output[\"TrialRXAxisRaw\"]   = \"\"\n",
    "\n",
    "    inst_info = info[\"Instrument\"].split()\n",
    "    \n",
    "    output[\"InstrumentModel\"]  = inst_info[-1].split(\"-\")[0]\n",
    "    output[\"InstrumentSerialNumber\"] = inst_info[-1].split(\"-\")[1][:4]\n",
    "    output[\"InstrumentSoftwareVersion\"] = inst_info[-1].split(\"/\")[-1]\n",
    "    \n",
    "    output[\"LowPatientReliabilityStatus\"] = info[\"Reliability\"]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4826a5",
   "metadata": {},
   "source": [
    "#### `fovea_probability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82016819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fovea_probability(filename):\n",
    "    \n",
    "    # Convert the pdf to an image\n",
    "    img = np.array(convert_from_path(os.path.join(input_dir, filename))[0])\n",
    "    sub = img[585:615, 495:525]\n",
    "    avg = sub.mean()\n",
    "    \n",
    "    # Check if probability is needed\n",
    "    if info[\"Fovea\"] == \"Off\":\n",
    "        return \"\"\n",
    "    \n",
    "    # Determine the probability value according to the mean pixel value\n",
    "    if avg == 255.0:\n",
    "        return \"Not Significant\"\n",
    "    if avg < 125.0:\n",
    "        return \"P < 0.5%\"\n",
    "    if (avg >= 125.0 and avg < 190.0):\n",
    "        return \"P < 1%\"\n",
    "    if (avg >= 190.0 and avg < 225.0):\n",
    "        return \"P < 2%\"\n",
    "    if (avg >= 225.0 and avg < 247.0):\n",
    "        return \"P < 5%\"\n",
    "    if (avg >= 247.0 and avg < 255.0):\n",
    "        return \"Not Significant\"       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d36bb",
   "metadata": {},
   "source": [
    "#### `format_matrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aefb7c8",
   "metadata": {},
   "source": [
    "Extracts and formats text from a VF plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79f7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_matrix(pdf, bbox, prefix = \"Thr\"):\n",
    "    \n",
    "    # Helper function to determine if metadata is inputted correctly\n",
    "    def value_check(values, bboxes, diff):\n",
    "    \n",
    "        # Rows and columns for each bbox\n",
    "        out  = values\n",
    "        rows = list(map(lambda x: x[1], bboxes))\n",
    "        cols = list(map(lambda x: x[0], bboxes))\n",
    "\n",
    "        levels = [4, 6, 8, 8, 8, 8, 6, 8]\n",
    "\n",
    "        # Check each row has the proper number of entries\n",
    "        start = 0\n",
    "        count = 0\n",
    "        for i, x in enumerate(levels):\n",
    "\n",
    "            rblock = rows[start:(start + x)]\n",
    "            cblock = cols[start:(start + x)]\n",
    "            check  = pd.Series(rblock).nunique()\n",
    "\n",
    "            if check != 1:\n",
    "                idx = start + pd.Series(cblock[:-1]).diff().idxmax()\n",
    "                out = out[:idx] + [out[idx][0]] + [out[idx][1]] + out[(idx+1):]\n",
    "\n",
    "                count += 1\n",
    "                start -= 1\n",
    "\n",
    "            if len(rblock) != x:\n",
    "                idx = start + pd.Series(cblock).diff().idxmax()\n",
    "                out = out[:idx] + [out[idx][0]] + [out[idx][1]] + out[(idx+1):]\n",
    "\n",
    "                count += 1\n",
    "                start -= 1\n",
    "\n",
    "            if count == diff:\n",
    "                break\n",
    "\n",
    "            start += x\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # Ordering\n",
    "    if info[\"Eye\"] == \"OS\":\n",
    "        ORDER = ['T9_S21', 'T3_S21', 'N3_S21', 'N9_S21', 'T15_S15',\n",
    "                 'T9_S15', 'T3_S15', 'N3_S15', 'N9_S15', 'N15_S15',\n",
    "                 'T21_S9', 'T15_S9', 'T9_S9', 'T3_S9', 'N3_S9','N9_S9',\n",
    "                 'N15_S9', 'N21_S9', 'T21_S3', 'T15_S3', 'T9_S3','T3_S3',\n",
    "                 'N3_S3', 'N9_S3', 'N15_S3', 'N21_S3', 'N27_S3', \n",
    "                 'T21_I3', 'T15_I3', 'T9_I3', 'T3_I3', 'N3_I3', 'N9_I3',\n",
    "                 'N15_I3', 'N21_I3', 'N27_I3', 'T21_I9', 'T15_I9',\n",
    "                 'T9_I9', 'T3_I9', 'N3_I9', 'N9_I9', 'N15_I9', 'N21_I9',\n",
    "                 'T15_I15', 'T9_I15', 'T3_I15', 'N3_I15', 'N9_I15',\n",
    "                 'N15_I15', 'T9_I21', 'T3_I21', 'N3_I21', 'N9_I21'\n",
    "                ]\n",
    "        \n",
    "    else:\n",
    "        ORDER = ['N9_S21', 'N3_S21', 'T3_S21', 'T9_S21', 'N15_S15',\n",
    "                 'N9_S15', 'N3_S15', 'T3_S15', 'T9_S15', 'T15_S15',\n",
    "                 'N21_S9', 'N15_S9', 'N9_S9', 'N3_S9', 'T3_S9',\n",
    "                 'T9_S9', 'T15_S9', 'T21_S9', 'N27_S3', 'N21_S3',\n",
    "                 'N15_S3', 'N9_S3', 'N3_S3', 'T3_S3', 'T9_S3',\n",
    "                 'T15_S3', 'T21_S3', 'N27_I3', 'N21_I3', 'N15_I3',\n",
    "                 'N9_I3', 'N3_I3', 'T3_I3', 'T9_I3', 'T15_I3',\n",
    "                 'T21_I3', 'N21_I9', 'N15_I9', 'N9_I9', 'N3_I9',\n",
    "                 'T3_I9', 'T9_I9', 'T15_I9', 'T21_I9', 'N15_I15',\n",
    "                 'N9_I15', 'N3_I15', 'T3_I15', 'T9_I15', 'T15_I15',\n",
    "                 'N9_I21', 'N3_I21', 'T3_I21', 'T9_I21']\n",
    "        \n",
    "    ORDER.remove(\"T15_S3\")\n",
    "    ORDER.remove(\"T15_I3\")\n",
    "    \n",
    "    mat = pdf.extract([\n",
    "        (\"values\", f'LTTextLineHorizontal:in_bbox({bbox})')\n",
    "    ])\n",
    "    \n",
    "    query = mat[\"values\"]\n",
    "    \n",
    "    if query[0].layout.get_text() == 'MD Threshold exceeded.\\n':\n",
    "        return output, ORDER\n",
    "    \n",
    "    values = []\n",
    "    bboxes = []\n",
    "    \n",
    "    for i, x in enumerate(query):\n",
    "        values.append(x.layout.get_text().strip())\n",
    "        bboxes.append(x.layout.bbox + (i,))\n",
    "        \n",
    "    bboxes.sort(key = lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    new_idx = [x[-1] for x in bboxes]\n",
    "    values  = list(pd.Series(values)[new_idx])\n",
    "    values = \" \".join(values).split()\n",
    "    \n",
    "    # Check for incorrect values\n",
    "    if len(values) < 52:\n",
    "        values = value_check(values, bboxes, 52 - len(values))\n",
    "    \n",
    "    # Remove blind spots\n",
    "    if prefix == \"Thr\":\n",
    "        if info[\"Eye\"] == \"OS\":\n",
    "            blind_spots = [19, 28]\n",
    "        else:\n",
    "            blind_spots = [25, 34]\n",
    "\n",
    "        del values[blind_spots[1]]\n",
    "        del values[blind_spots[0]]\n",
    "        \n",
    "    # Unlist values\n",
    "    else:\n",
    "        values = list(map(lambda x: x.strip().split(), values))\n",
    "        values = sum(values, [])\n",
    "        \n",
    "    # Order the plot points    \n",
    "    tab_order = [x + \"_\" + prefix for x in ORDER]\n",
    "    output[tab_order] = values\n",
    "    \n",
    "    return output, ORDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b52f6",
   "metadata": {},
   "source": [
    "#### `probability_points`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f416000",
   "metadata": {},
   "source": [
    "Extracts and converts symbols to their respective probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efde897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_points(filename, start1, end1, start2, end2, box_width):\n",
    "    \n",
    "    # Convert the pdf to an image\n",
    "    img = np.array(convert_from_path(os.path.join(input_dir, filename))[0])\n",
    "    \n",
    "    # Loop through each box and calculate mean pixel value\n",
    "    PROBS = []\n",
    "    for i in np.arange(start1, end1, box_width):\n",
    "        for j in np.arange(start2, end2, box_width):\n",
    "            \n",
    "            point = img[i:(i+box_width), j:(j+box_width)]\n",
    "            value = point[2:(box_width - 2), 7:(box_width-2)].mean()\n",
    "            \n",
    "            # Determine the probability value according to the mean pixel value\n",
    "            if value == 255.0:\n",
    "                continue\n",
    "            if value < 125.0:\n",
    "                PROBS.append(\"P < 0.5%\")\n",
    "            if (value >= 125.0 and value < 190.0):\n",
    "                PROBS.append(\"P < 1%\")\n",
    "            if (value >= 190.0 and value < 225.0):\n",
    "                PROBS.append(\"P < 2%\")\n",
    "            if (value >= 225.0 and value < 247.0):\n",
    "                PROBS.append(\"P < 5%\")\n",
    "            if (value >= 247.0 and value < 255.0):\n",
    "                PROBS.append(\"Not Significant\")\n",
    "                \n",
    "    return PROBS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb4a2a",
   "metadata": {},
   "source": [
    "#### Extracting Text from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6fcd8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PDF(s) processed\n",
      "2 PDF(s) processed\n",
      "3 PDF(s) processed\n",
      "4 PDF(s) processed\n",
      "5 PDF(s) processed\n",
      "6 PDF(s) processed\n",
      "7 PDF(s) processed\n",
      "8 PDF(s) processed\n",
      "9 PDF(s) processed\n",
      "10 PDF(s) processed\n",
      "11 PDF(s) processed\n",
      "12 PDF(s) processed\n",
      "13 PDF(s) processed\n",
      "14 PDF(s) processed\n",
      "15 PDF(s) processed\n",
      "16 PDF(s) processed\n",
      "17 PDF(s) processed\n",
      "18 PDF(s) processed\n",
      "19 PDF(s) processed\n",
      "20 PDF(s) processed\n",
      "21 PDF(s) processed\n",
      "22 PDF(s) processed\n",
      "23 PDF(s) processed\n",
      "24 PDF(s) processed\n",
      "25 PDF(s) processed\n",
      "26 PDF(s) processed\n",
      "27 PDF(s) processed\n",
      "28 PDF(s) processed\n",
      "29 PDF(s) processed\n",
      "30 PDF(s) processed\n",
      "31 PDF(s) processed\n",
      "32 PDF(s) processed\n",
      "33 PDF(s) processed\n",
      "34 PDF(s) processed\n",
      "35 PDF(s) processed\n",
      "36 PDF(s) processed\n",
      "37 PDF(s) processed\n",
      "38 PDF(s) processed\n",
      "39 PDF(s) processed\n",
      "40PDF #40 was skipped (VO1055_OS_20181004_SFA_24-2_0809.pdf)\n",
      "41 PDF(s) processed\n",
      "42PDF #42 was skipped (VO1505_OS_20181004_SFA_24-2_0816.pdf)\n",
      "43PDF #43 was skipped (VO0220_OS_20181004_SFA_24-2_0827.pdf)\n",
      "44 PDF(s) processed\n"
     ]
    }
   ],
   "source": [
    "CSVS_242 = []\n",
    "for i, x in enumerate(files):\n",
    "    \n",
    "    try:\n",
    "        # Create an empty DataFrame\n",
    "        output = pd.DataFrame(columns=cols, index=[0])\n",
    "\n",
    "        # Load in each pdf\n",
    "        pdf = pq.PDFQuery(os.path.join(input_dir, x))\n",
    "        pdf.load()\n",
    "\n",
    "        # Key value pairs\n",
    "        info = key_value_output(pdf)\n",
    "\n",
    "        # Populate output\n",
    "        output = clean_output(info, output)\n",
    "\n",
    "        # Plot points\n",
    "        try:\n",
    "            output, ORDER = format_matrix(pdf, '\"123.612215, 450, 312.100175, 620\"')\n",
    "            output, ORDER = format_matrix(pdf, '\"0, 330, 210, 450\"', \"TD\")\n",
    "            output, ORDER = format_matrix(pdf, '\"210, 330, 400, 450\"', \"PD\")\n",
    "        except:\n",
    "            # Move the files that throw errors into a different directory\n",
    "            if not os.path.isdir(os.path.join(input_dir, \"error_files\")):\n",
    "                os.makedirs(os.path.join(input_dir, \"error_files\"))\n",
    "\n",
    "            shutil.move(os.path.join(input_dir, x), os.path.join(input_dir, \"error_files\", x))\n",
    "\n",
    "        # Calculate the probability points for both plots\n",
    "        if info[\"Eye\"] == \"OD\":\n",
    "            TDP = probability_points(x, 1498, 1762, 188, 485, 33)\n",
    "            PDP = probability_points(x, 1498, 1762, 692, 989, 33)\n",
    "        else:\n",
    "            TDP = probability_points(x, 1498, 1762, 221, 518, 33)\n",
    "            PDP = probability_points(x, 1498, 1762, 725, 1022, 33)\n",
    "\n",
    "        tdp_order = [x + \"_TDP\" for x in ORDER]\n",
    "        pdp_order = [x + \"_PDP\" for x in ORDER]\n",
    "\n",
    "        try:\n",
    "            output[tdp_order] = TDP\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            output[pdp_order] = PDP\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # Fovea probability variable\n",
    "        output[\"FovealThresholdProb\"] = fovea_probability(x)\n",
    "\n",
    "        if info[\"Test Pattern\"] == \"Central 24-2 Threshold Test\":\n",
    "            CSVS_242.append(output)\n",
    "\n",
    "        print(str(i + 1) + \" PDF(s) processed\")\n",
    "        \n",
    "    except:\n",
    "        print(\"PDF #\" + str(i + 1) + \" was skipped\" + f\" ({x})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the batch of files as a csv\n",
    "DF = pd.concat(CSVS_242)\n",
    "DF.to_csv(os.path.join(output_dir, \"24_2.csv\"), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
